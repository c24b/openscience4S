{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual analysis of the Article 9\n",
    "\n",
    "Analyse the main keywords relationship on the debate to find out the key and core concept of the debate on Open Science\n",
    "that took place inside the Digital Consultation on the French \n",
    "\n",
    "We will try then to enlight the main argument position of the groups involved in this debate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "#importing modules\n",
    "#lecture des json\n",
    "import json\n",
    "#text-minig\n",
    "import re\n",
    "#viz\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#calcul\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ARTICLE 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_vo(art_file = \"./article_9.json\"):\n",
    "    with open(art_file, \"r\") as f:\n",
    "        article9 = json.load(f)\n",
    "    return article9\n",
    "article9 = load_vo()\n",
    "#remembering it for later\n",
    "#versions = article9[\"versions\"]\n",
    "#arguments = article9[\"arguments\"]\n",
    "#sources = article9[\"sources\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposing the amendement(versions) on the Article9\n",
    "\n",
    "We will load the text law\n",
    "as it has been originally proposed by the governement inside **article9**\n",
    "* In a first draft we will concentrate ourself in the different modification proposed by the participants\n",
    "\n",
    "\n",
    "But before let's discover which information are stored in article9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYS OF THE ARTICLE: ['votes_mitige', 'versions_count', 'votes_total', 'article_link', 'answer', 'cat_id', 'body_links', 'ranking', 'arguments_count', 'body', 'sources', 'versions', 'votes_ok', 'votes_nok', 'arguments', 'author', 'updated_at', 'title', 'subtitle', 'sources_count', 'article_id', 'body_anchors', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "# here all the information keys on the article 9 in it's original version\n",
    "print(\"KEYS OF THE ARTICLE:\", list(article9.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concentrate ourself on the main body of the article. We will call it **VO** as it is the main original version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttitle:\n",
      " Section 2\n",
      "\tsubtitle:\n",
      " Travaux de recherche et de statistique\n",
      "\ttext:\n",
      " Au chapitre 3 du titre 3 du livre V du code de la recherche, il est inséré un article L. 533-4 ainsi rédigé :«Art. L. 533-4 –I. Lorsque un écrit scientifique, issu d’une activité de recherche financée au moins pour moitié par des fonds publics, est publié dans un périodique, un ouvrage paraissant au moins une fois par an, des actes de congrès ou de colloques ou des recueils de mélanges, son auteur, même en cas de cession exclusive à un éditeur, dispose du droit de mettre à disposition gratuitement sous une forme numérique, sous réserve des droits des éventuels coauteurs, la dernière version acceptée de son manuscrit par son éditeur et à l’exclusion du travail de mise en forme qui incombe à ce dernier, au terme d’un délai de douze mois pour les sciences, la technique et la médecine et de vingt-quatre mois pour les sciences humaines et sociales, à compter de date de la première publication. Cette mise à disposition ne peut donner lieu à aucune exploitation commerciale.« II. – Les dispositions du présent article sont d’ordre public et toute clause contraire à celles-ci est réputée non écrite. Elles ne s’appliquent pas aux contrats en cours. »\n",
      "\treferences:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "V0 = article9[\"body\"]\n",
    "\n",
    "print(\"\\ttitle:\\n\", article9[\"title\"])\n",
    "print(\"\\tsubtitle:\\n\", article9[\"subtitle\"])\n",
    "print(\"\\ttext:\\n\", article9[\"body\"])\n",
    "print(\"\\treferences:\\n\", article9[\"body_anchors\"])\n",
    "#print(\"arguments\", article9[\"arguments\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clean out the text removing all the ponctuation, number and small words by creating a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #text = text.decode(\"utf-8\")\n",
    "    #regex expression that says remove all the non alpha caracters\n",
    "    clean_text = re.sub('[^\\w]', ' ', text)\n",
    "    #split word\n",
    "    words = clean_text.split(' ')\n",
    "    #lowercas + filter small words such as article or prepositions\n",
    "    return [w.lower() for w in words if len(w) > 3 and w != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 keywords\n",
      "['chapitre', 'titre', 'livre', 'code', 'recherche', 'inséré', 'article', 'ainsi', 'rédigé', 'lorsque', 'écrit', 'scientifique', 'issu', 'activité', 'recherche', 'financée', 'moins', 'pour', 'moitié', 'fonds', 'publics', 'publié', 'dans', 'périodique', 'ouvrage', 'paraissant', 'moins', 'fois', 'actes', 'congrès', 'colloques', 'recueils', 'mélanges', 'auteur', 'même', 'cession', 'exclusive', 'éditeur', 'dispose', 'droit', 'mettre', 'disposition', 'gratuitement', 'sous', 'forme', 'numérique', 'sous', 'réserve', 'droits', 'éventuels', 'coauteurs', 'dernière', 'version', 'acceptée', 'manuscrit', 'éditeur', 'exclusion', 'travail', 'mise', 'forme', 'incombe', 'dernier', 'terme', 'délai', 'douze', 'mois', 'pour', 'sciences', 'technique', 'médecine', 'vingt', 'quatre', 'mois', 'pour', 'sciences', 'humaines', 'sociales', 'compter', 'date', 'première', 'publication', 'cette', 'mise', 'disposition', 'peut', 'donner', 'lieu', 'aucune', 'exploitation', 'commerciale', 'dispositions', 'présent', 'article', 'sont', 'ordre', 'public', 'toute', 'clause', 'contraire', 'celles', 'réputée', 'écrite', 'elles', 'appliquent', 'contrats', 'cours']\n"
     ]
    }
   ],
   "source": [
    "clean_V0 = clean_text(V0)\n",
    "print(len(clean_V0),\"keywords\")\n",
    "print(clean_V0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many versions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 versions\n"
     ]
    }
   ],
   "source": [
    "#+1 for original version\n",
    "versions_total = len(article9[\"versions\"])+1\n",
    "print(versions_total, \"versions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now we have a function to clean up text will will apply it to **ALL** versions of the article\n",
    "Remember: They are stored in 'versions' key of the main article9 dictionnary and they are composed with the same information of the original article but the main body text is stored in after. \n",
    "It means that for the moment we will make 2 operations:\n",
    "* create a main list with all the keywords\n",
    "* agregate in a list all the text of the different versions to differenciate them will will store the date of the version, the title and the bunch of words from the cleaned text.\n",
    "Let's do it first with the original version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "versions_text = []\n",
    "keywords = []\n",
    "versions_text.append([0, article9[\"created_at\"], clean_text(article9[\"body\"])])\n",
    "keywords.extend([w for w in clean_text(article9[\"body\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,version in enumerate(article9[\"versions\"]):\n",
    "    #i is the number of the version but we already have the original version at 0\n",
    "    i = i+1\n",
    "    #print(version.keys())\n",
    "    versions_text.append([i, version[\"created_at\"], clean_text(version[\"after\"])])\n",
    "    \n",
    "    \n",
    "    keywords.extend(clean_text(version[\"after\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 versions\n"
     ]
    }
   ],
   "source": [
    "print(len(versions_text), \"versions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pour': 327, 'forme': 218, 'mois': 218, 'disposition': 218, 'sciences': 218, 'éditeur': 218, 'moins': 218, 'sous': 218, 'mise': 218, 'recherche': 110, 'article': 110, 'moitié': 109, 'exclusive': 109, 'écrite': 109, 'périodique': 109, 'cession': 109, 'délai': 109, 'recueils': 109, 'donner': 109, 'contrats': 109, 'commerciale': 109, 'manuscrit': 109, 'appliquent': 109, 'celles': 109, 'lieu': 109, 'exclusion': 109, 'scientifique': 109, 'actes': 109, 'exploitation': 109, 'auteur': 109, 'contraire': 109, 'colloques': 109, 'publication': 109, 'réserve': 109, 'version': 109, 'médecine': 109, 'cours': 109, 'sont': 109, 'financée': 109, 'ouvrage': 109, 'réputée': 109, 'aucune': 109, 'peut': 109, 'toute': 109, 'écrit': 109, 'clause': 109, 'terme': 109, 'droits': 109, 'congrès': 109, 'humaines': 109, 'technique': 109, 'lorsque': 109, 'même': 109, 'publié': 109, 'mettre': 109, 'travail': 109, 'sociales': 109, 'numérique': 109, 'dispositions': 109, 'public': 109, 'première': 109, 'dans': 109, 'vingt': 109, 'acceptée': 109, 'fonds': 109, 'mélanges': 109, 'dernier': 109, 'elles': 109, 'activité': 109, 'gratuitement': 109, 'publics': 109, 'présent': 109, 'dernière': 109, 'cette': 109, 'fois': 109, 'paraissant': 109, 'dispose': 109, 'douze': 109, 'ordre': 109, 'incombe': 109, 'issu': 109, 'quatre': 109, 'éventuels': 109, 'compter': 109, 'date': 109, 'auteurs': 108, 'dudroit': 108, 'chapitre': 1, 'rédigé': 1, 'ainsi': 1, 'livre': 1, 'titre': 1, 'coauteurs': 1, 'inséré': 1, 'droit': 1, 'code': 1})\n"
     ]
    }
   ],
   "source": [
    "#Let's first agregate all the keywords of all the version and discover the top keywords\n",
    "from collections import Counter\n",
    "#print(len(keywords))\n",
    "#print(keywords)\n",
    "keywords_freq = Counter(keywords)\n",
    "print(keywords_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 2 changed this ['chapitre', 'rédigé', 'ainsi', 'livre', 'auteurs', 'titre', 'coauteurs', 'inséré', 'droit', 'code', 'dudroit']\n",
      "Version 3 changed this []\n",
      "Version 4 changed this []\n",
      "Version 5 changed this []\n",
      "Version 6 changed this []\n",
      "Version 7 changed this []\n",
      "Version 8 changed this []\n",
      "Version 9 changed this []\n",
      "Version 10 changed this []\n",
      "Version 11 changed this []\n",
      "Version 12 changed this []\n",
      "Version 13 changed this []\n",
      "Version 14 changed this []\n",
      "Version 15 changed this []\n",
      "Version 16 changed this []\n",
      "Version 17 changed this []\n",
      "Version 18 changed this []\n",
      "Version 19 changed this []\n",
      "Version 20 changed this []\n",
      "Version 21 changed this []\n",
      "Version 22 changed this []\n",
      "Version 23 changed this []\n",
      "Version 24 changed this []\n",
      "Version 25 changed this []\n",
      "Version 26 changed this []\n",
      "Version 27 changed this []\n",
      "Version 28 changed this []\n",
      "Version 29 changed this []\n",
      "Version 30 changed this []\n",
      "Version 31 changed this []\n",
      "Version 32 changed this []\n",
      "Version 33 changed this []\n",
      "Version 34 changed this []\n",
      "Version 35 changed this []\n",
      "Version 36 changed this []\n",
      "Version 37 changed this []\n",
      "Version 38 changed this []\n",
      "Version 39 changed this []\n",
      "Version 40 changed this []\n",
      "Version 41 changed this []\n",
      "Version 42 changed this []\n",
      "Version 43 changed this []\n",
      "Version 44 changed this []\n",
      "Version 45 changed this []\n",
      "Version 46 changed this []\n",
      "Version 47 changed this []\n",
      "Version 48 changed this []\n",
      "Version 49 changed this []\n",
      "Version 50 changed this []\n",
      "Version 51 changed this []\n",
      "Version 52 changed this []\n",
      "Version 53 changed this []\n",
      "Version 54 changed this []\n",
      "Version 55 changed this []\n",
      "Version 56 changed this []\n",
      "Version 57 changed this []\n",
      "Version 58 changed this []\n",
      "Version 59 changed this []\n",
      "Version 60 changed this []\n",
      "Version 61 changed this []\n",
      "Version 62 changed this []\n",
      "Version 63 changed this []\n",
      "Version 64 changed this []\n",
      "Version 65 changed this []\n",
      "Version 66 changed this []\n",
      "Version 67 changed this []\n",
      "Version 68 changed this []\n",
      "Version 69 changed this []\n",
      "Version 70 changed this []\n",
      "Version 71 changed this []\n",
      "Version 72 changed this []\n",
      "Version 73 changed this []\n",
      "Version 74 changed this []\n",
      "Version 75 changed this []\n",
      "Version 76 changed this []\n",
      "Version 77 changed this []\n",
      "Version 78 changed this []\n",
      "Version 79 changed this []\n",
      "Version 80 changed this []\n",
      "Version 81 changed this []\n",
      "Version 82 changed this []\n",
      "Version 83 changed this []\n",
      "Version 84 changed this []\n",
      "Version 85 changed this []\n",
      "Version 86 changed this []\n",
      "Version 87 changed this []\n",
      "Version 88 changed this []\n",
      "Version 89 changed this []\n",
      "Version 90 changed this []\n",
      "Version 91 changed this []\n",
      "Version 92 changed this []\n",
      "Version 93 changed this []\n",
      "Version 94 changed this []\n",
      "Version 95 changed this []\n",
      "Version 96 changed this []\n",
      "Version 97 changed this []\n",
      "Version 98 changed this []\n",
      "Version 99 changed this []\n",
      "Version 100 changed this []\n",
      "Version 101 changed this []\n",
      "Version 102 changed this []\n",
      "Version 103 changed this []\n",
      "Version 104 changed this []\n",
      "Version 105 changed this []\n",
      "Version 106 changed this []\n",
      "Version 107 changed this []\n",
      "Version 108 changed this []\n",
      "Version 109 changed this []\n"
     ]
    }
   ],
   "source": [
    "#Lets see the changes between versions\n",
    "\n",
    "for version in versions_text:\n",
    "    #we already stored 3 info nb, data and keywords\n",
    "    nb, date, keywords = version\n",
    "    \n",
    "    \n",
    "    if nb == 0:\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        old_kw = versions_text[int(nb-1)][2]\n",
    "        \n",
    "        #let's compare what they didn't change\n",
    "        commons = set(keywords).intersection(old_kw)\n",
    "        changed = set(old_kw) ^ set(keywords)\n",
    "        print(\"Version\", nb+1, \"changed this\", list(changed))\n",
    "        #print(commons)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing changed between versions so far. The debate is not focused on the main text but in it's interpretation and implications. The arguments and the comments of the modifications may be more relevant that tracking the changes on the versions. \n",
    "We can't see changes, excluding the first (on the legal context of the article the references of the existing article) \n",
    "also maybe because the main modifications were light and not included in our filter system for word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In a second draft we will concentrate on modification comment proposed to enlight a particular position on the text.\n",
    "\n",
    "## Article9: Exposing the comment on modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments = []\n",
    "comments_keywords = []\n",
    "\n",
    "#versions_text.append([0, article9[\"created_at\"], clean_text(article9[\"body\"])])\n",
    "#keywords.extend([w for w in clean_text(article9[\"body\"])])\n",
    "#Pour rappel\n",
    "#print(article9[\"versions\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'tous': 4, 'utiliser': 2, 'fins': 2, 'commerciales': 2, 'recherche': 2, 'doivent': 2, 'pouvoir': 2, 'etat': 2, 'appartient': 2, 'financée': 2})\n"
     ]
    }
   ],
   "source": [
    "for i,version in enumerate(article9[\"versions\"]):\n",
    "    #i is the number of the version but we already have the original version at 0\n",
    "    i = i+1\n",
    "    if version[\"comment\"] is not None:\n",
    "    \n",
    "        comments_keywords = clean_text(version[\"comment\"])\n",
    "    \n",
    "    #print(version.keys())\n",
    "        comments.append([i, version[\"created_at\"],version[\"author\"], version[\"votes_total\"], version[\"arguments_count\"], keywords])\n",
    "        comments_keywords.extend(comments_keywords)\n",
    "\n",
    "comment_keywords_freq = Counter(comments_keywords)\n",
    "print(comment_keywords_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see the different keywords in the law and in the comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chapitre', 'moitié', 'écrite', 'périodique', 'délai', 'version', 'recueils', 'appartient', 'donner', 'contrats', 'rédigé', 'travail', 'ainsi', 'etat', 'commerciale', 'manuscrit', 'livre', 'celles', 'première', 'appliquent', 'forme', 'commerciales', 'lieu', 'exclusive', 'auteurs', 'scientifique', 'exploitation', 'auteur', 'contraire', 'colloques', 'publication', 'exclusion', 'réserve', 'médecine', 'mois', 'paraissant', 'sont', 'publié', 'cours', 'fins', 'disposition', 'tous', 'actes', 'ouvrage', 'réputée', 'peut', 'toute', 'écrit', 'mettre', 'clause', 'terme', 'titre', 'droits', 'pour', 'aucune', 'coauteurs', 'cession', 'congrès', 'humaines', 'technique', 'pouvoir', 'lorsque', 'même', 'sciences', 'sociales', 'numérique', 'éditeur', 'doivent', 'public', 'dans', 'vingt', 'acceptée', 'fonds', 'mélanges', 'utiliser', 'dernier', 'elles', 'activité', 'inséré', 'dispositions', 'article', 'droit', 'gratuitement', 'moins', 'sous', 'publics', 'présent', 'dernière', 'cette', 'fois', 'code', 'dispose', 'douze', 'mise', 'ordre', 'incombe', 'issu', 'dudroit', 'quatre', 'éventuels', 'compter', 'date'}\n",
      "{'utiliser', 'commerciales', 'pouvoir', 'appartient', 'fins', 'doivent', 'tous', 'etat'}\n",
      "{'recherche', 'financée'}\n"
     ]
    }
   ],
   "source": [
    "added = set(comment_keywords_freq.keys()) - set(keywords_freq.keys())\n",
    "diff = set(comment_keywords_freq.keys()) ^ set(keywords_freq.keys())\n",
    "common  = set(comment_keywords_freq.keys()).intersection(keywords_freq.keys())\n",
    "print(diff)\n",
    "print(added)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article9: Exposing the arguments of Article9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  the concentrate ourself in the arguments exposed by the different participants involved in this active debate\n",
    "But first we have to aggregate all the versions of the text to enlight the dynamic of this debate and be able to analyse \n",
    "the arguments raised by a version.\n",
    "\n",
    "NB: the versions of the article are mostly the entrypoint to see the evolution of the participation over time. And only the major version has finally been taken in count for the arguments and the votes.\n",
    "\n",
    "In a first intent we will focus on the arguments exposed in the original version. Just to simplify the task\n",
    "\n",
    "### Arguments in Original Version\n",
    "\n",
    "Before asking questions, we want to understand the kind of information stored into the arguments of the original version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['body', 'author', 'updated_at', 'article_id', 'link', 'created_at', 'id', 'votes_count'])\n"
     ]
    }
   ],
   "source": [
    "print(article9[\"arguments\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 arguments for the original version\n"
     ]
    }
   ],
   "source": [
    "arguments_total = len(article9[\"arguments\"])\n",
    "print(arguments_total, \"arguments for the original version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many authors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 unique argumentators\n",
      "Counter({'federationnationaledelapressedinformationspecialisee': 4, 'robertodicosmo': 4, 'francoisrobinet': 3, 'sylvainribault': 2, 'alexanderdoria': 2, 'sylviepommier': 2, 'institutderechercheenproprieteintellectuelleirpi1': 2, 'bernardlegras': 2, 'lucoger': 2, 'heinerwittmann': 2, 'comitedethiqueducnrscomets': 2, 'erickajfasz': 2, 'dsa': 2, 'superchaton': 2, 'oliviersandre': 2, 'mti131': 2, 'peaucelle': 2, 'charlotterecapet': 2, 'vincentreverdy': 2, 'frederichelein': 2, 'williampaul': 1, 'thomasheams': 1, 'venet': 1, 'florianmoreau': 1, 'peterwolf': 1, 'mathieurouard': 1, 'blazyolivier': 1, 'aureliedudezert': 1, 'isabelleramade': 1, 'stminternationalassociationofscientifictechnicalandmedicalpublishers': 1, 'albertcohen': 1, 'francoischaroy': 1, 'remipeyre': 1, 'mathieustumpfguntz': 1, 'vincentdanjean': 1, 'jonathancrequer': 1, 'martinecoppet': 1, 'filippoalbertoedoardonuccio': 1, 'sylviegrandeuryburon': 1, 'emmanuelbeffara': 1, 'pn': 1, 'aymericpoulainmaubant': 1, 'capellilaurent': 1, 'emmanueldupoux': 1, 'laurentlamy': 1, 'pierrecourtieu': 1, 'instancesnumeriquesdumedef': 1, 'olivierdessombz': 1, 'associationdesarchivistesfrancais': 1, 'christofschoch': 1, 'stefanefermigier': 1, 'kareng': 1, 'annemariemottaz': 1, 'lucfruchter': 1, 'samsond': 1, 'alexandrekeledjian': 1, 'thibaultlietard': 1, 'francoisgeze': 1, 'blaisegenest': 1, 'emmanuelhadoux': 1, 'jacquesbittoun': 1, 'christianjoschke': 1, 'danielretureau': 1, 'anamariaalvarezlage': 1, 'sebastienmonchamps': 1, 'arnaudlegrand': 1, 'delenne': 1, 'inradistodilehologne': 1, 'guillaumecarret': 1, 'pierrecrescenzo': 1, 'yanncochard': 1, 'nicolasdumoulin': 1, 'fredericboulanger': 1, 'claudegout': 1, 'jeanyvescharbonnel': 1, 'oliviermorin1': 1, 'emmanuellepicard': 1, 'michelvert': 1, 'marionaubry': 1, 'editionsdalloz': 1, 'nicolas': 1, 'cyrilcohen': 1, 'davidmonniaux': 1, 'villeneuve': 1, 'patrickechegut': 1, 'isabellegouat': 1, 'djp1': 1, 'cedriccorrege': 1, 'laurentromary': 1, 'marlenedelhaye': 1, 'frederiquelangue': 1, 'patrickbaillot': 1, 'hervecourtois': 1, 'sgl': 1, 'patrickberthet': 1, 'julienbarre': 1, 'syndicatnationaldeledition': 1, 'plessismarc': 1, 'davidvantyghem': 1, 'stephanevial1': 1, 'marinecgossa': 1, 'geoffreythiesset': 1, 'hcyinguyenvan': 1, 'marcelpoualion': 1, 'nathanfrenot': 1, 'linefournier': 1, 'benjaminperet': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "authors = [arg[\"author\"] for arg in article9[\"arguments\"]]\n",
    "authors_freq = Counter(authors)\n",
    "print(len(authors_freq), \"unique argumentators\")\n",
    "print(authors_freq)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most voted arguments?\n",
    "arguments are identified by its number\n",
    "in a list (nb, votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (2, 1), (3, 4), (4, 8), (5, 3), (6, 8), (7, 3), (8, 2), (9, 2), (10, 7), (11, 0), (12, 1), (13, 0), (14, 0), (15, 3), (16, 0), (17, 9), (18, 7), (19, 5), (20, 4), (21, 5), (22, 6), (23, 1), (24, 4), (25, 2), (26, 3), (27, 4), (28, 5), (29, 3), (30, 4), (31, 4), (32, 4), (33, 0), (34, 1), (35, 0), (36, 0), (37, 6), (38, 6), (39, 16), (40, 14), (41, 13), (42, 12), (43, 13), (44, 4), (45, 14), (46, 10), (47, 11), (48, 17), (49, 13), (50, 7), (51, 11), (52, 10), (53, 13), (54, 7), (55, 4), (56, 1), (57, 1), (58, 1), (59, 1), (60, 21), (61, 6), (62, 10), (63, 1), (64, 4), (65, 10), (66, 16), (67, 18), (68, 6), (69, 14), (70, 9), (71, 20), (72, 7), (73, 30), (74, 1), (75, 19), (76, 13), (77, 6), (78, 20), (79, 9), (80, 15), (81, 11), (82, 9), (83, 6), (84, 0), (85, 13), (86, 18), (87, 11), (88, 3), (89, 7), (90, 15), (91, 12), (92, 7), (93, 2), (94, 2), (95, 2), (96, 2), (97, 5), (98, 8), (99, 35), (100, 38), (101, 14), (102, 9), (103, 4), (104, 6), (105, 6), (106, 10), (107, 2), (108, 4), (109, 6), (110, 9), (111, 4), (112, 8), (113, 9), (114, 18), (115, 14), (116, 22), (117, 24), (118, 3), (119, 5), (120, 3), (121, 29), (122, 26), (123, 10), (124, 32), (125, 0), (126, 10), (127, 20), (128, 9), (129, 12), (130, 24), (131, 22), (132, 16)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "votes = [(i+1, int(arg[\"votes_count\"])) for i, arg in enumerate(article9[\"arguments\"])]\n",
    "print(votes)\n",
    "#top_votes = sorted(votes.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Retrieve specific arguments by filter\n",
    "def filter_arguments_by_author(author):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"author\"] == author]\n",
    "def filter_arguments_by_id(arg_id):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"id\"] == arg_id]\n",
    "def filter_arguments_by_link(link):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"link\"] == link]\n",
    "def filter_arguments_by_score(votes_count):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"votes_count\"] >= votes_count]\n",
    "def filter_arguments_by_pos(pos):\n",
    "    return article9[pos]\n",
    "def filter_arguments_by_maxrange(maxrange):\n",
    "    return article9[:maxrange]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular authors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('robertodicosmo', 111), ('federationnationaledelapressedinformationspecialisee', 52), ('mti131', 46), ('frederichelein', 40), ('albertcohen', 32), ('marlenedelhaye', 29), ('emmanuelhadoux', 26), ('isabellegouat', 22), ('guillaumecarret', 21), ('alexanderdoria', 21), ('marinecgossa', 20), ('inradistodilehologne', 20), ('christofschoch', 20), ('thibaultlietard', 19), ('benjaminperet', 18), ('peaucelle', 18), ('francoisgeze', 18), ('francoischaroy', 18), ('pierrecourtieu', 17), ('syndicatnationaldeledition', 16), ('sebastienmonchamps', 16), ('stephanevial1', 15), ('blaisegenest', 15), ('sylviepommier', 15), ('villeneuve', 14), ('cyrilcohen', 14), ('oliviermorin1', 14), ('dsa', 14), ('claudegout', 14), ('geoffreythiesset', 13), ('editionsdalloz', 13), ('emmanuellepicard', 13), ('pierrecrescenzo', 13), ('delenne', 12), ('comitedethiqueducnrscomets', 12), ('julienbarre', 11), ('vincentreverdy', 11), ('patrickbaillot', 11), ('nicolasdumoulin', 11), ('capellilaurent', 11), ('sgl', 10), ('marionaubry', 10), ('fredericboulanger', 10), ('alexandrekeledjian', 10), ('samsond', 10), ('jonathancrequer', 10), ('sylvainribault', 10), ('hervecourtois', 9), ('frederiquelangue', 9), ('laurentromary', 9), ('bernardlegras', 9), ('vincentdanjean', 9), ('linefournier', 8), ('davidmonniaux', 8), ('nathanfrenot', 7), ('superchaton', 7), ('michelvert', 7), ('olivierdessombz', 7), ('thomasheams', 7), ('hcyinguyenvan', 6), ('patrickberthet', 6), ('arnaudlegrand', 6), ('aymericpoulainmaubant', 6), ('pn', 6), ('emmanuelbeffara', 6), ('martinecoppet', 6), ('aureliedudezert', 6), ('williampaul', 6), ('charlotterecapet', 5), ('cedriccorrege', 5), ('nicolas', 5), ('erickajfasz', 5), ('jacquesbittoun', 5), ('kareng', 5), ('plessismarc', 4), ('patrickechegut', 4), ('yanncochard', 4), ('heinerwittmann', 4), ('danielretureau', 4), ('stefanefermigier', 4), ('laurentlamy', 4), ('sylviegrandeuryburon', 4), ('blazyolivier', 4), ('peterwolf', 4), ('florianmoreau', 4), ('lucoger', 3), ('annemariemottaz', 3), ('emmanueldupoux', 3), ('francoisrobinet', 3), ('mathieurouard', 3), ('oliviersandre', 2), ('filippoalbertoedoardonuccio', 2), ('remipeyre', 2), ('venet', 2), ('marcelpoualion', 1), ('djp1', 1), ('christianjoschke', 1), ('associationdesarchivistesfrancais', 1), ('mathieustumpfguntz', 1), ('stminternationalassociationofscientifictechnicalandmedicalpublishers', 1), ('davidvantyghem', 0), ('jeanyvescharbonnel', 0), ('anamariaalvarezlage', 0), ('lucfruchter', 0), ('instancesnumeriquesdumedef', 0), ('institutderechercheenproprieteintellectuelleirpi1', 0), ('isabelleramade', 0)]\n"
     ]
    }
   ],
   "source": [
    "author_votes = []\n",
    "for author in authors_freq.keys():\n",
    "    args = filter_arguments_by_author(author)\n",
    "    votes = sum([int(arg[\"votes_count\"]) for arg in args])\n",
    "    author_votes.append((author, votes))\n",
    "\n",
    "author_votes = sorted(author_votes, key=lambda x: x[1])[::-1]\n",
    "print(author_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this few statistics, let's concentrate ourself on text doing the same simple work that on VERSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords\n",
    "\n",
    "A global view on keywords used in all the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pour', 136), ('dans', 90), ('embargo', 79), ('plus', 74), ('éditeurs', 72), ('recherche', 70), ('article', 55), ('scientifiques', 54), ('être', 49), ('mais', 45), ('sont', 43), ('accès', 43), ('articles', 40), ('chercheurs', 38), ('publics', 37), ('avec', 37), ('publication', 37), ('mois', 36), ('travail', 33), ('éditeur', 31)]\n"
     ]
    }
   ],
   "source": [
    "#global kw for args\n",
    "args_keywords = []\n",
    "for arg in article9[\"arguments\"]:\n",
    "    text = arg[\"body\"]\n",
    "    kw = clean_text(text)\n",
    "    args_keywords.extend(kw)\n",
    "    \n",
    "args_kw_freq = Counter(args_keywords)\n",
    "#print(args_kw_freq)\n",
    "#for display reason get the most 20 used\n",
    "\n",
    "print(args_kw_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-9a7ae20d3b1c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-9a7ae20d3b1c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Compare it to the text amendement\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Compare it to the text amendement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moitié', 'cession', 'aucune', 'pour', 'coauteurs', 'périodique', 'congrès', 'humaines', 'délai', 'recueils', 'version', 'technique', 'lorsque', 'même', 'donner', 'contrats', 'recherche', 'rédigé', 'ainsi', 'travail', 'commerciale', 'manuscrit', 'celles', 'sciences', 'forme', 'sociales', 'première', 'date', 'numérique', 'éditeur', 'exclusive', 'lieu', 'auteurs', 'public', 'dans', 'vingt', 'scientifique', 'acceptée', 'exploitation', 'auteur', 'contraire', 'fonds', 'colloques', 'publication', 'mélanges', 'dernier', 'exclusion', 'réserve', 'elles', 'médecine', 'mois', 'publié', 'sont', 'activité', 'article', 'droit', 'gratuitement', 'disposition', 'moins', 'sous', 'publics', 'présent', 'dernière', 'financée', 'actes', 'ouvrage', 'cette', 'fois', 'code', 'peut', 'dispose', 'toute', 'écrit', 'mettre', 'douze', 'clause', 'incombe', 'mise', 'terme', 'titre', 'issu', 'quatre', 'éventuels', 'compter', 'droits'}\n"
     ]
    }
   ],
   "source": [
    "added = set(args_kw_freq.keys()) - set(keywords_freq.keys())\n",
    "diff = set(args_kw_freq.keys()) ^ set(keywords_freq.keys())\n",
    "common  = set(args_kw_freq.keys()).intersection(keywords_freq.keys())\n",
    "#print(diff)\n",
    "#print(added)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network analysis: Commons words between authors\n",
    "* First analyse the words used by a specific author in it's different version \n",
    "we will store it inside a dict along with its votes for further use\n",
    "* Then compare each set of keywords used by one author to another\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "author_kw = defaultdict.fromkeys(authors_freq.keys(), {})\n",
    "for author in author_kw.keys():\n",
    "    args = filter_arguments_by_author(author)\n",
    "    votes = sum([int(arg[\"votes_count\"]) for arg in args])\n",
    "    kw = []\n",
    "    for arg in args:\n",
    "        kw.extend(clean_text(arg[\"body\"]))\n",
    "    author_kw[author] = {\"keywords\": kw, \"votes\": votes}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-a84130b0b40c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-a84130b0b40c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Now we have the information for each author of an argument\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Now we have the information for each author of an argument\n",
    "we can compare the word in commons by authores. \n",
    "We will examine the couples and make a simple file with the couple and the keywords in commons.\n",
    "Ready?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "couples = []\n",
    "for couple in combinations(authors_freq.keys(), 2):\n",
    "        userA, userB = couple\n",
    "        commons_kw = set(author_kw[userA][\"keywords\"]).intersection(author_kw[userB][\"keywords\"])\n",
    "        diff_kw = set(author_kw[userA][\"keywords\"])^ set(author_kw[userB][\"keywords\"])\n",
    "        couples.append([userA, userB, \",\".join(commons_kw),str(len(commons_kw)), \",\".join(diff_kw), str(len(diff_kw))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"arguments_auth_kw.csv\",\"w\") as f:\n",
    "    f.write('\\t'.join([\"authorA\",\"authorB\",\"commons_kw\",\"common_nb\",\"diff_kw\", \"diff_nb\"])+\"\\n\")\n",
    "    for couple in couples:\n",
    "        f.write('\\t'.join(list(couple))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Network analysis inside Cortext Manager\n",
    "with open(\"author_kw.csv\",\"w\") as f:\n",
    "    line = [\"author\", \"keywords\"]\n",
    "    f.write('\\t'.join(line)+\"\\n\")\n",
    "    for author,val in author_kw.items():\n",
    "        line = [author, \"***\".join(val[\"keywords\"])]\n",
    "        f.write('\\t'.join(line)+\"\\n\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Tag analysis inside Gargantext Plateform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text and the weight and the author of each argument are respectively stored in body, votes_count, author "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many votes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store in a simple list:\n",
    "* the author\n",
    "* the nb of votes (total)\n",
    "* the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arguments_V0 = []\n",
    "for arg in article9[\"arguments\"]:\n",
    "    arguments_V0.append([arg[\"author\"], arg[\"votes_count\"], clean_text(arg[\"body\"])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Argumenting dynamic\n",
    "\n",
    "But first a quick overview of the arguments dynamics.\n",
    "Arguments exposed on the original version is stored in article9[\"arguments\"] meanwhile each version had it's own debate with arguments linked on this particular version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arguments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(article9[\"arguments\"]),\"arguments in the original version\")\n",
    "#verification\n",
    "arguments_nb = sum([version[\"arguments_count\"] for version in article9[\"versions\"]])\n",
    "#for i,version in enumerate(article9[\"versions\"]):\n",
    "#    print(version[\"arguments_count\"])\n",
    "print(arguments_nb, \"in the other versions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arguments_by_version_count = [(0, article9[\"created_at\"], len(article9[\"arguments\"])]\n",
    "for \n",
    "def show_nb_arguments_by_versions(vs):\n",
    "    #for k,v in vs.items():\n",
    "    #    print(len(v[\"votes\"]),\"votes sur la version:\" , k )\n",
    "    N = len(vs)\n",
    "    votes_nb = [len(v[\"votes\"])  for v in vs.values()]\n",
    "    \n",
    "    plt.title(\"Repartition des votes simples par version\")\n",
    "    plt.ylabel('Nb votes')\n",
    "    #pylab.xlim([0,108])\n",
    "    #pylab.xlim([0,N])\n",
    "    plt.plot(votes_nb,color='r')\n",
    "    #votes_declares = [v[\"total_votes\"] for v in vs.values()]\n",
    "        \n",
    "    #votes_declares = [len(v[\"total_votes\"]) for v in vs.values()]\n",
    "    #plt.plot(votes_declares,color='b')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "show_nb_votes_by_versions(versions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
