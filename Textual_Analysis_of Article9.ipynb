{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual analysis of the Article 9\n",
    "\n",
    "Analyse the main keywords relationship on the debate to find out the key and core concept of the debate on Open Science\n",
    "that took place inside the Digital Consultation on the French \n",
    "\n",
    "We will try then to enlight the main argument position of the groups involved in this debate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "#importing modules\n",
    "#lecture des json\n",
    "import json\n",
    "#text-minig\n",
    "import re\n",
    "#viz\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#calcul\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ARTICLE 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_vo(art_file = \"./article_9.json\"):\n",
    "    with open(art_file, \"r\") as f:\n",
    "        article9 = json.load(f)\n",
    "    return article9\n",
    "article9 = load_vo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Before any kind of analysis, let's discover which information are stored in article9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYS OF THE ARTICLE: ['arguments_count', 'versions_count', 'created_at', 'updated_at', 'body', 'subtitle', 'title', 'votes_total', 'votes_mitige', 'arguments', 'cat_id', 'votes_nok', 'votes_ok', 'sources', 'article_id', 'sources_count', 'author', 'article_link', 'ranking', 'body_links', 'versions', 'body_anchors', 'answer']\n"
     ]
    }
   ],
   "source": [
    "# here all the information keys on the article 9 in it's original version\n",
    "print(\"KEYS OF THE ARTICLE:\", list(article9.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article9 stores the accepted version \n",
    "\n",
    "along with other versions, arguments and sources inside the corresponding key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remembering it for later\n",
    "versions = article9[\"versions\"] # all the versions without the original one\n",
    "arguments = article9[\"arguments\"] #arguments on the original version or other versionS???\n",
    "sources = article9[\"sources\"] #all the arguments without the votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versions of the Article9\n",
    "\n",
    "* In a first draft we will concentrate ourself in the different modification proposed by the participants\n",
    "\n",
    "Analysis objectives\n",
    "\n",
    "* Show the modifications dynamics:\n",
    "    * over time\n",
    "    * over \n",
    "\n",
    "Data Manipulation:\n",
    "\n",
    "* **Build a referential call versions9 in a list**\n",
    "* **Provide some method to ease filter on version facets**\n",
    "* **\n",
    "\n",
    "Data Analysis Objectives:\n",
    "\n",
    "* **Show the modifications dynamics over changes**\n",
    "* **Analyse the sociolects of each authors**\n",
    "* **Enlight the different communities by the use of specific sociolects**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Isolate Original Version\n",
    "The main version corresponds to the original version proposed by the governement.\n",
    "\n",
    "We will call it **VO** as it is the main original version.\n",
    "This version will be defined with the smallest common denominator with the other version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V0 = article9[\"body\"]\n",
    "\n",
    "print(\"\\ttitle:\\n\", article9[\"title\"])\n",
    "print(\"\\tsubtitle:\\n\", article9[\"subtitle\"])\n",
    "print(\"\\ttext:\\n\", article9[\"body\"])\n",
    "print(\"\\treferences:\\n\", article9[\"body_anchors\"])\n",
    "#print(\"arguments\", article9[\"arguments\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clean out the text removing all the ponctuation, number and small words by creating a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #text = text.decode(\"utf-8\")\n",
    "    #regex expression that says remove all the non alpha caracters\n",
    "    clean_text = re.sub('[^\\w]', ' ', text)\n",
    "    #split word\n",
    "    words = clean_text.split(' ')\n",
    "    #lowercas + filter small words such as article or prepositions\n",
    "    return [w.lower() for w in words if len(w) > 3 and w != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_V0 = clean_text(V0)\n",
    "print(len(clean_V0),\"keywords\")\n",
    "print(clean_V0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many versions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#+1 for original version\n",
    "versions_total = len(article9[\"versions\"])+1\n",
    "print(versions_total, \"versions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now we have a function to clean up text will will apply it to **ALL** versions of the article\n",
    "Remember: They are stored in 'versions' key of the main article9 dictionnary and they are composed with the same information of the original article but the main body text is stored in after. \n",
    "It means that for the moment we will make 2 operations:\n",
    "* create a main list with all the keywords\n",
    "* agregate in a list all the text of the different versions to differenciate them will will store the date of the version, the title and the bunch of words from the cleaned text.\n",
    "Let's do it first with the original version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "versions_text = []\n",
    "keywords = []\n",
    "versions_text.append([0, article9[\"created_at\"], clean_text(article9[\"body\"])])\n",
    "keywords.extend([w for w in clean_text(article9[\"body\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,version in enumerate(article9[\"versions\"]):\n",
    "    #i is the number of the version but we already have the original version at 0\n",
    "    i = i+1\n",
    "    #print(version.keys())\n",
    "    versions_text.append([i, version[\"created_at\"], clean_text(version[\"before\"])])\n",
    "    keywords.extend(clean_text(version[\"before\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(versions_text), \"versions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's first agregate all the keywords of all the version and discover the top keywords\n",
    "from collections import Counter\n",
    "#print(len(keywords))\n",
    "#print(keywords)\n",
    "keywords_freq = Counter(keywords)\n",
    "print(keywords_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lets see the changes between versions\n",
    "\n",
    "for version in versions_text:\n",
    "    #we already stored 3 info nb, data and keywords\n",
    "    nb, date, keywords = version\n",
    "    \n",
    "    \n",
    "    if nb == 0:\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        old_kw = versions_text[int(nb-1)][2]\n",
    "        \n",
    "        #let's compare what they didn't change\n",
    "        commons = set(keywords).intersection(old_kw)\n",
    "        changed = set(old_kw) ^ set(keywords)\n",
    "        print(\"Version\", nb+1, \"changed this\", list(changed))\n",
    "        #print(commons)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing changed between versions so far. The debate is not focused on the main text but in it's interpretation and implications. The arguments and the comments of the modifications may be more relevant that tracking the changes on the versions. \n",
    "We can't see changes, excluding the first (on the legal context of the article the references of the existing article) \n",
    "also maybe because the main modifications were light and not included in our filter system for word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In a second draft we will concentrate on modification comment proposed to enlight a particular position on the text.\n",
    "\n",
    "## Article9: Exposing the comment on modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments = []\n",
    "comments_keywords = []\n",
    "comments_v = []\n",
    "\n",
    "#versions_text.append([0, article9[\"created_at\"], clean_text(article9[\"body\"])])\n",
    "#keywords.extend([w for w in clean_text(article9[\"body\"])])\n",
    "#Pour rappel\n",
    "#print(article9[\"versions\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'tous': 4, 'doivent': 2, 'commerciales': 2, 'financÃ©e': 2, 'utiliser': 2, 'fins': 2, 'etat': 2, 'pouvoir': 2, 'appartient': 2, 'recherche': 2})\n"
     ]
    }
   ],
   "source": [
    "for i,version in enumerate(article9[\"versions\"]):\n",
    "    #i is the number of the version but we already have the original version at 0\n",
    "    #i = i+1\n",
    "    if version[\"comment\"] is not None:\n",
    "    \n",
    "        comments_keywords = clean_text(version[\"comment\"])\n",
    "        comments_v.append([i, comments_keywords, version[\"author\"]])\n",
    "    #print(version.keys())\n",
    "        comments.append([i, version[\"created_at\"],version[\"author\"], version[\"votes_total\"], version[\"arguments_count\"], keywords])\n",
    "        comments_keywords.extend(comments_keywords)\n",
    "\n",
    "comment_keywords_freq = Counter(comments_keywords)\n",
    "print(comment_keywords_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* See keywords between versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_comments = []\n",
    "for comment in comments_v:\n",
    "    v_id, author, keywords = comment\n",
    "    if v_id == 1:\n",
    "        pass\n",
    "    else:\n",
    "        last_kw = comments_v[v_id-1][1] \n",
    "        last_author = \n",
    "        added = set(keywords) - set(last_kw)\n",
    "        removed = set(last_kw) - set(keywords) \n",
    "        commons = set(keywords).intersection(last_kw)\n",
    "        diff_comments()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see the different keywords in the law and in the comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "added = set(comment_keywords_freq.keys()) - set(keywords_freq.keys())\n",
    "diff = set(comment_keywords_freq.keys()) ^ set(keywords_freq.keys())\n",
    "common  = set(comment_keywords_freq.keys()).intersection(keywords_freq.keys())\n",
    "print(diff)\n",
    "print(added)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article9: Exposing the arguments of Article9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  the concentrate ourself in the arguments exposed by the different participants involved in this active debate\n",
    "But first we have to aggregate all the versions of the text to enlight the dynamic of this debate and be able to analyse \n",
    "the arguments raised by a version.\n",
    "\n",
    "NB: the versions of the article are mostly the entrypoint to see the evolution of the participation over time. And only the major version has finally been taken in count for the arguments and the votes.\n",
    "\n",
    "In a first intent we will focus on the arguments exposed in the original version. Just to simplify the task\n",
    "\n",
    "### Arguments in Original Version\n",
    "\n",
    "Before asking questions, we want to understand the kind of information stored into the arguments of the original version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(article9[\"arguments\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arguments_total = len(article9[\"arguments\"])\n",
    "print(arguments_total, \"arguments for the original version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many authors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "authors = [arg[\"author\"] for arg in article9[\"arguments\"]]\n",
    "authors_freq = Counter(authors)\n",
    "print(len(authors_freq), \"unique argumentators\")\n",
    "print(authors_freq)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most voted arguments?\n",
    "arguments are identified by its number\n",
    "in a list (nb, votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "votes = [(i+1, int(arg[\"votes_count\"])) for i, arg in enumerate(article9[\"arguments\"])]\n",
    "print(votes)\n",
    "#top_votes = sorted(votes.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Retrieve specific arguments by filter\n",
    "def filter_arguments_by_author(author):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"author\"] == author]\n",
    "def filter_arguments_by_id(arg_id):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"id\"] == arg_id]\n",
    "def filter_arguments_by_link(link):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"link\"] == link]\n",
    "def filter_arguments_by_score(votes_count):\n",
    "    return [arg for arg in article9[\"arguments\"] if arg[\"votes_count\"] >= votes_count]\n",
    "def filter_arguments_by_pos(pos):\n",
    "    return article9[pos]\n",
    "def filter_arguments_by_maxrange(maxrange):\n",
    "    return article9[:maxrange]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular authors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_votes = []\n",
    "for author in authors_freq.keys():\n",
    "    args = filter_arguments_by_author(author)\n",
    "    votes = sum([int(arg[\"votes_count\"]) for arg in args])\n",
    "    author_votes.append((author, votes))\n",
    "\n",
    "author_votes = sorted(author_votes, key=lambda x: x[1])[::-1]\n",
    "print(author_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this few statistics, let's concentrate ourself on text doing the same simple work that on VERSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keywords\n",
    "\n",
    "A global view on keywords used in all the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#global kw for args\n",
    "args_keywords = []\n",
    "for arg in article9[\"arguments\"]:\n",
    "    text = arg[\"body\"]\n",
    "    kw = clean_text(text)\n",
    "    args_keywords.extend(kw)\n",
    "    \n",
    "args_kw_freq = Counter(args_keywords)\n",
    "#print(args_kw_freq)\n",
    "#for display reason get the most 20 used\n",
    "\n",
    "print(args_kw_freq.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Compare it to the text amendement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "added = set(args_kw_freq.keys()) - set(keywords_freq.keys())\n",
    "diff = set(args_kw_freq.keys()) ^ set(keywords_freq.keys())\n",
    "common  = set(args_kw_freq.keys()).intersection(keywords_freq.keys())\n",
    "#print(diff)\n",
    "#print(added)\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network analysis: Commons words between authors\n",
    "* First analyse the words used by a specific author in it's different version \n",
    "we will store it inside a dict along with its votes for further use\n",
    "* Then compare each set of keywords used by one author to another\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "author_kw = defaultdict.fromkeys(authors_freq.keys(), {})\n",
    "for author in author_kw.keys():\n",
    "    args = filter_arguments_by_author(author)\n",
    "    votes = sum([int(arg[\"votes_count\"]) for arg in args])\n",
    "    kw = []\n",
    "    for arg in args:\n",
    "        kw.extend(clean_text(arg[\"body\"]))\n",
    "    author_kw[author] = {\"keywords\": kw, \"votes\": votes}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we have the information for each author of an argument\n",
    "we can compare the word in commons by authores. \n",
    "We will examine the couples and make a simple file with the couple and the keywords in commons.\n",
    "Ready?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "couples = []\n",
    "for couple in combinations(authors_freq.keys(), 2):\n",
    "        userA, userB = couple\n",
    "        commons_kw = set(author_kw[userA][\"keywords\"]).intersection(author_kw[userB][\"keywords\"])\n",
    "        diff_kw = set(author_kw[userA][\"keywords\"])^ set(author_kw[userB][\"keywords\"])\n",
    "        couples.append([userA, userB, \",\".join(commons_kw),str(len(commons_kw)), \",\".join(diff_kw), str(len(diff_kw))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"arguments_auth_kw.csv\",\"w\") as f:\n",
    "    f.write('\\t'.join([\"authorA\",\"authorB\",\"commons_kw\",\"common_nb\",\"diff_kw\", \"diff_nb\"])+\"\\n\")\n",
    "    for couple in couples:\n",
    "        f.write('\\t'.join(list(couple))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Network analysis inside Cortext Manager\n",
    "## Generating a simple TSV file\n",
    "\n",
    "with open(\"author_kw.csv\",\"w\") as f:\n",
    "    line = [\"author\", \"keywords\"]\n",
    "    f.write('\\t'.join(line)+\"\\n\")\n",
    "    for author,val in author_kw.items():\n",
    "        line = [author, \"***\".join(val[\"keywords\"])]\n",
    "        f.write('\\t'.join(line)+\"\\n\")\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Tag analysis inside Gargantext Plateform\n",
    "import datetime\n",
    "with open(\"arguments.csv\", \"w\") as f:\n",
    "    line = [\"author\", \"text\", \"votes\", \"date\"]\n",
    "    f.write('\\t'.join(line)+\"\\n\")\n",
    "    for arg in article9[\"arguments\"]:\n",
    "        date = datetime.datetime.strptime(arg[\"created_at\"], \"%Y-%m-%dT%H:%M:%S%z\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        line = [arg[\"author\"], arg[\"body\"], arg[\"votes_count\"], date]\n",
    "        #print(line)\n",
    "        f.write('\\t'.join(line)+\"\\n\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text and the weight and the author of each argument are respectively stored in body, votes_count, author "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many votes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store in a simple list:\n",
    "* the author\n",
    "* the nb of votes (total)\n",
    "* the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arguments_V0 = []\n",
    "for arg in article9[\"arguments\"]:\n",
    "    arguments_V0.append([arg[\"author\"], arg[\"votes_count\"], clean_text(arg[\"body\"])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Argumenting dynamic\n",
    "\n",
    "But first a quick overview of the arguments dynamics.\n",
    "Arguments exposed on the original version is stored in article9[\"arguments\"] meanwhile each version had it's own debate with arguments linked on this particular version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arguments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(article9[\"arguments\"]),\"arguments in the original version\")\n",
    "#verification\n",
    "arguments_nb = sum([version[\"arguments_count\"] for version in article9[\"versions\"]])\n",
    "#for i,version in enumerate(article9[\"versions\"]):\n",
    "#    print(version[\"arguments_count\"])\n",
    "print(arguments_nb, \"in the other versions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arguments_by_version_count = [(0, article9[\"created_at\"], len(article9[\"arguments\"])]\n",
    "for \n",
    "def show_nb_arguments_by_versions(vs):\n",
    "    #for k,v in vs.items():\n",
    "    #    print(len(v[\"votes\"]),\"votes sur la version:\" , k )\n",
    "    N = len(vs)\n",
    "    votes_nb = [len(v[\"votes\"])  for v in vs.values()]\n",
    "    \n",
    "    plt.title(\"Repartition des votes simples par version\")\n",
    "    plt.ylabel('Nb votes')\n",
    "    #pylab.xlim([0,108])\n",
    "    #pylab.xlim([0,N])\n",
    "    plt.plot(votes_nb,color='r')\n",
    "    #votes_declares = [v[\"total_votes\"] for v in vs.values()]\n",
    "        \n",
    "    #votes_declares = [len(v[\"total_votes\"]) for v in vs.values()]\n",
    "    #plt.plot(votes_declares,color='b')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "show_nb_votes_by_versions(versions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
